{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\soham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prior probability of positive class is 0.5579681007907787\n",
      "The prior probability of negative class is 0.44203189920922126\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from csv import QUOTE_NONE\n",
    "\n",
    "# Read the SST data\n",
    "sst_data = pd.read_csv(\"SST-2/train.tsv\", sep=\"\\t\")\n",
    "\n",
    "#Take 100 rows in validation set\n",
    "validation_set = sst_data[:100]\n",
    "\n",
    "#Take 100 rows in test set\n",
    "test_set = sst_data[100:200]\n",
    "\n",
    "#put remaining rows in training set\n",
    "training_set = sst_data[200:]\n",
    "\n",
    "# initialize the positive and negative count\n",
    "positive_count = (training_set['label'] == 1).sum()\n",
    "negative_count = (training_set['label'] == 0).sum()\n",
    "\n",
    "#length of training set\n",
    "training_length = len(training_set)\n",
    "\n",
    "#getting prior probability for positive and negative classes\n",
    "prior_probab_positive = positive_count / training_length\n",
    "prior_probab_negative = negative_count / training_length\n",
    "\n",
    "#printing prior probability of both classes\n",
    "print(f\"The prior probability of positive class is {prior_probab_positive}\")\n",
    "print(f\"The prior probability of negative class is {prior_probab_negative}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenized first sentence is: ['<s>', 'told', 'in', 'scattered', 'fashion', '</s>']\n",
      "The vocabulary size of training set is 14813\n"
     ]
    }
   ],
   "source": [
    "# A function to tokenized sentence and padding with start and end symbols\n",
    "def sentence_tokenizer(sentence):\n",
    "    tokenize_sentence = sentence.split()\n",
    "    tokenize_sentence.insert(0, '<s>')\n",
    "    tokenize_sentence.append('</s>')\n",
    "\n",
    "    return tokenize_sentence\n",
    "\n",
    "#tokenized the entire training dataset\n",
    "tokenized_training_set = training_set['sentence'].apply(sentence_tokenizer)\n",
    "\n",
    "#getting the first line from tokenized training set and printing it\n",
    "first_line_trainingset = tokenized_training_set.iloc[0]\n",
    "print(f\"The tokenized first sentence is: {first_line_trainingset}\")\n",
    "\n",
    "#Getting a list of tokenized sentences in the training set\n",
    "tokenizedlist_trainingset = tokenized_training_set.tolist()\n",
    "\n",
    "total_tokens = []\n",
    "\n",
    "#getting the unique words in total_tokens list\n",
    "for i in tokenizedlist_trainingset:\n",
    "    for j in i:\n",
    "        total_tokens.append(j)\n",
    "\n",
    "vocabulary_set = set(total_tokens)\n",
    "\n",
    "\n",
    "vocabulary_size = len(vocabulary_set)                                       #getting the count of the unique words\n",
    "\n",
    "print(f\"The vocabulary size of training set is {vocabulary_size}\")          #printing the count of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of bigram ('<s>', 'the') = 4450\n"
     ]
    }
   ],
   "source": [
    "# Function to count the biagram frequencies\n",
    "def count_biagram_frequencies(tokenized_sequences):\n",
    "    bigram_counts = {}                                                                  #Initializing a dictionary\n",
    "\n",
    "    for tokens in tokenized_sequences:\n",
    "        for i in range(len(tokens)-1):  \n",
    "            first_word = tokens[i]                                                       # getting the first word\n",
    "            second_word = tokens[i+1]                                                    # getting the second word\n",
    "\n",
    "            bigram = (first_word, second_word)                                              \n",
    "            if bigram not in bigram_counts:                                              # Getting the bigram counts\n",
    "                bigram_counts[bigram]=0\n",
    "            bigram_counts[bigram]+=1\n",
    "    return bigram_counts\n",
    "\n",
    "\n",
    "# Setting the bigram counts value in bigram_counts variable\n",
    "bigram_counts = count_biagram_frequencies(tokenizedlist_trainingset)\n",
    "\n",
    "#printing frequency of bigram '<s>' and 'the'\n",
    "print(f\"Frequency of bigram ('<s>', 'the') = {bigram_counts.get(('<s>', 'the'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log probability with alpha= 0.001 is  -1.0250904304166832\n",
      "The log probability with alpha= 0.5 is  -6.172912066128204\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def smoothed_biagram_probab(wm, wm_1, bigram_counts, alpha, vocabulary_size):\n",
    "\n",
    "    # count of biagram(wm, wm-1)\n",
    "    count_bigram = bigram_counts.get((wm_1, wm), 0)\n",
    "\n",
    "    #count of unigram(wm-1)\n",
    "    count_unigram = 0\n",
    "    for i, j in bigram_counts.items():\n",
    "        if i[0] == wm_1:\n",
    "            count_unigram +=j\n",
    "\n",
    "    # To get smoothed probability using alpha smoothing formula\n",
    "    smoothed_probability = (count_bigram + alpha) / (count_unigram + alpha * vocabulary_size)\n",
    "\n",
    "    # TO get the negative log probability\n",
    "    calc_negative_log_probab = math.log(smoothed_probability)\n",
    "\n",
    "    return calc_negative_log_probab\n",
    "\n",
    "\n",
    "word = 'award'\n",
    "previous_word = 'academy'\n",
    "# passing the parameters with alpha as 0.001 to the smoothed function to get the negative log probability\n",
    "negative_log_probab1 = smoothed_biagram_probab(word, previous_word, bigram_counts, 0.001, 14813)\n",
    "\n",
    "# passing the parameters with alpha as 0.5 to the smoothed function to get the negative log probability\n",
    "negative_log_probab2 = smoothed_biagram_probab(word, previous_word, bigram_counts, 0.5, 14813)\n",
    "\n",
    "# printing the negative log probability with alpha 0.001\n",
    "print(f\"The log probability with alpha= 0.001 is  {negative_log_probab1}\")\n",
    "\n",
    "# printing the negative log probability with alpha 0.5\n",
    "print(f\"The log probability with alpha= 0.5 is  {negative_log_probab2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log probability of first sentence is -69.91754047795261\n",
      "The log probability of second sentence is -113.38139766388028\n"
     ]
    }
   ],
   "source": [
    "# Function for getting the log probability of a sentence\n",
    "def sentence_log_probab(sentence, bigram_counts, alpha, vocabulary_size):\n",
    "    # Splitting the sentence into words\n",
    "    words_of_sentence = sentence.split()\n",
    "\n",
    "    #Initializing the log probability    \n",
    "    log_probability = 0.0\n",
    "\n",
    "    # Looping through the words in sentence\n",
    "    for i in range(1, len(words_of_sentence)):\n",
    "        #Calculating negative log probability\n",
    "        negative_log_probab = smoothed_biagram_probab(words_of_sentence[i], words_of_sentence[i-1], bigram_counts, alpha, vocabulary_size)\n",
    "        log_probability+= negative_log_probab\n",
    "\n",
    "    return log_probability\n",
    "\n",
    "# Initializing first sentence, getting its log probability and printing it.\n",
    "first_sentence = \"this was a really great movie but it was a little too long.\"\n",
    "log_probab1 = sentence_log_probab(first_sentence, bigram_counts, 0.1, 14813)\n",
    "print(f\"The log probability of first sentence is {log_probab1}\")\n",
    "\n",
    "# Initializing second sentence, getting its log probability and printing it.\n",
    "second_sentence = \"long too little a was it but movie great really a was this.\"\n",
    "log_probab2 = sentence_log_probab(second_sentence, bigram_counts, 0.1, 14813)\n",
    "print(f\"The log probability of second sentence is {log_probab2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log likelihood estimate for alpha as 0.001 is -3493.4581923786996\n",
      "The log likelihood estimate for alpha as 0.01 is -3924.884625422819\n",
      "The log likelihood estimate for alpha as 0.1 is -4795.08551812413\n",
      "\n",
      "The best alpha is 0.001\n"
     ]
    }
   ],
   "source": [
    "# All the alpha values\n",
    "all_alpha_values = [0.001, 0.01, 0.1]\n",
    "\n",
    "# initializing best log chances variable\n",
    "best_log_chances = 0\n",
    "\n",
    "# setting selected alpha as 0 initially\n",
    "selected_alpha = 0\n",
    "\n",
    "# looping through all the alpha values\n",
    "for alpha in all_alpha_values:\n",
    "    approximate_log_likelihood = 0\n",
    "\n",
    "    # Applying log probability function to each sentence in the validation set\n",
    "    for i in validation_set['sentence']:\n",
    "        approximate_log_likelihood += sentence_log_probab(i, bigram_counts, alpha, vocabulary_size)\n",
    "\n",
    "    # Printing the approximate log likelihood for current alpha\n",
    "    print(f\"The log likelihood estimate for alpha as {alpha} is {approximate_log_likelihood}\")\n",
    "\n",
    "    # Check which alpha gives the highest result\n",
    "    if best_log_chances == 0 or approximate_log_likelihood > best_log_chances:\n",
    "        best_log_chances = approximate_log_likelihood\n",
    "        selected_alpha = alpha\n",
    "\n",
    "# Printing the best alpha\n",
    "print(f\"\\nThe best alpha is {selected_alpha}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48522\n",
      "44518\n",
      "[-7.253391238232215, -9.519098921068263, -29.500317356639187, -43.00077704367012, -85.28020375046799, -30.84617820330108, -282.7169887981055, -26.085111406125037, -101.56336397163857, -53.83487418285453, -45.634460865658795, -3.3870862838919096, -95.6515466858324, -9.601853191031529, -73.49957423406723, -9.935380221314594, -192.5321198303463, -0.5834534852765388, -33.70501625313465, -173.02094432022972, -20.221760679446504, -23.185443911875076, -56.043350349467836, -110.30155724876961, -6.707926328068044, -107.99565989530217, -51.99499545528104, -38.163413478073316, -99.59810925611275, -17.10886455913073, -5.859496960799376, -88.8079853881296, -59.32297414072547, -9.935380221314594, -0.5834534852765388, -64.2603825041634, -71.75029148389306, -11.020180820821025, -22.095669013648184, -91.34455391009922, -21.54453748649091, -37.401668495187025, -125.38157160366583, -23.44038735914226, -32.4307466688923, -29.87100312373693, -82.79217564513755, -2.7887710491694855, -148.5139799920184, -3.5063517691721033, -61.67926810801431, -7.168811042123843, -8.518541607842211, -16.890068371597643, -95.60190536640835, -86.56670169711806, -3.0259185092506646, -56.047446203279286, -13.139769358567818, -20.2600139709929, -113.59313668945217, -12.12098512790286, -27.32029917434731, -16.09859206793892, -12.396893230471346, -86.24582763658825, -18.303131910946956, -33.82105193994409, -52.50169667483655, -195.12782473620504, -7.2779218495206806, -0.5834534852765388, -82.39840443658508, -37.88130512723824, -47.86038350448938, -42.04685063314639, -12.12642781437146, -12.913180228521785, -20.612241370904556, -31.321428357962485, -109.60917573338436, -38.65447869190934, -22.137688624688927, -282.50237524225383, -36.06761006601039, -17.980750222654695, -81.56288172137242, -279.9534183635842, -25.00048157834238, -78.53448614002022, -142.53496181109833, -34.14522119689832, -8.464870213309442, -26.454111808027356, -32.04250228465877, -37.36546028366635, -48.708161814428145, -34.53922033966471, -101.92606810626694, -26.326655769115753]\n",
      "[-7.3658940892692755, -4.876726208585536, -15.953963876952347, -75.59973142625003, -33.85716446898409, -64.85116719011071, -187.02469942270437, -15.362518776561023, -206.00119721413213, -50.98544428399632, -40.5633983345001, -2.6213187327821514, -187.61842748179362, -27.9619084870599, -31.064270514920757, -1.7742113032453206, -112.03119646642777, -0.8163732293519702, -65.73950881359107, -109.08226248580567, -53.033349260804, -22.32323373801088, -15.229736327557898, -77.7241363500541, -20.614131047953364, -41.11995296623464, -105.04388101832693, -85.48431899978821, -224.17816205064187, -9.57635830968399, -21.587037810510935, -30.59427043017287, -89.29347733475973, -1.9945205060362672, -0.8163732293519702, -131.8449021189115, -178.76565030368394, -19.10085097920838, -19.210060918958114, -36.21073380592857, -48.619931043999614, -89.58167418092776, -207.3492613129058, -21.054385478891014, -13.14459112688745, -54.76843712409831, -51.94212220783729, -10.681379795069818, -80.93337527009999, -4.331009637952157, -125.34436765236791, -7.2733642198316435, -19.061579265245534, -35.193783336951775, -35.522529591508565, -37.34531980515335, -10.229246198738238, -133.39026767519408, -28.964650325455988, -9.658698945931151, -270.9748886061733, -13.479623320247814, -12.009124467594134, -49.76215085873546, -21.633050810749705, -37.91407162822776, -53.41820746125113, -75.33191585212978, -58.41871245174537, -97.7568240492621, -16.973713150878403, -0.8163732293519702, -61.90745139036571, -20.730851793821707, -110.66643975449612, -23.877848832450592, -16.26925644974896, -16.674981261404838, -9.760809630001228, -82.73023773700692, -47.16570537705239, -12.39729265860165, -66.53329262124915, -139.25851634143515, -69.61849939316234, -45.13276265621742, -40.214433406771924, -129.8819870676839, -44.81890516853446, -34.603548498338334, -62.20773113313038, -50.281260774091606, -9.22555321897901, -8.952559666950455, -30.383608234116682, -16.09662995002254, -83.19885890028893, -137.28181553159118, -30.34604188485272, -9.484760672292754]\n",
      "Class Distribution - Predicted Positive: 53 | Predicted Negative: 47\n",
      "Predicted Accuracy : 92.0\n"
     ]
    }
   ],
   "source": [
    "# Seprating our positive and negative datasets\n",
    "training_set_pos = training_set[training_set['label'] == 1]\n",
    "training_set_neg = training_set[training_set['label'] == 0]\n",
    "\n",
    "#Calculating vocabulary size for positive and negative sets\n",
    "positive_vocabulary_size = len(set(''.join(training_set_pos['sentence']).split()))\n",
    "negative_vocabulary_size = len(set(''.join(training_set_neg['sentence']).split()))\n",
    "\n",
    "# Sentence tokenizer function\n",
    "def sentence_tokenizer2(sentence):\n",
    "    tokenize_sentence1 = sentence.split()\n",
    "    return tokenize_sentence1\n",
    "\n",
    "# Getting positive and negative bigram counts\n",
    "positive_bigram_counts = count_biagram_frequencies(training_set_pos['sentence'].apply(sentence_tokenizer2).tolist())\n",
    "negative_bigram_counts = count_biagram_frequencies(training_set_neg['sentence'].apply(sentence_tokenizer2).tolist())\n",
    "\n",
    "print(len(positive_bigram_counts))\n",
    "print(len(negative_bigram_counts))\n",
    "# setting positive and negative score as a list\n",
    "total_positive_score = []\n",
    "total_negative_score = []\n",
    "\n",
    "# looping through test set to get the positive and negative score\n",
    "for sentence in test_set['sentence']:\n",
    "    test_set_tokens = sentence_tokenizer2(sentence)\n",
    "\n",
    "    positive_score = math.log(prior_probab_positive)\n",
    "    negative_score = math.log(prior_probab_negative)\n",
    "\n",
    "    # Applying the smoothed bigram probab function to get the positive and negative score\n",
    "    for i in range(1, len(test_set_tokens)):\n",
    "        word = test_set_tokens[i]\n",
    "        previous_word = test_set_tokens[i-1]\n",
    "\n",
    "        positive_score += smoothed_biagram_probab(word, previous_word, positive_bigram_counts, selected_alpha, positive_vocabulary_size)\n",
    "        negative_score += smoothed_biagram_probab(word, previous_word, negative_bigram_counts, selected_alpha, negative_vocabulary_size)\n",
    "\n",
    "    total_positive_score.append(positive_score)\n",
    "    total_negative_score.append(negative_score)\n",
    "\n",
    "predicted_labels = []\n",
    "\n",
    "# Appending 1 as positive and 0 as negative in predicted labels\n",
    "for i in range(len(test_set)):\n",
    "    if total_positive_score[i] > total_negative_score[i]:\n",
    "        predicted_labels.append(1)\n",
    "    else:\n",
    "        predicted_labels.append(0)\n",
    "\n",
    "# Getting the original labels from test set\n",
    "true_labels = test_set['label'].tolist()\n",
    "\n",
    "# Setting positive predicted and negative predicted\n",
    "positive_predicted =  predicted_labels.count(1)\n",
    "negative_predicted =  predicted_labels.count(0) \n",
    "\n",
    "print(total_positive_score)\n",
    "print(total_negative_score)\n",
    "# initializing accurate predictions as a list\n",
    "accurate_predictions = []\n",
    "\n",
    "# Appending 1 for correct prediction and 0 for incorrect prediction\n",
    "for true, predicted in zip(true_labels, predicted_labels):\n",
    "    if true == predicted:\n",
    "        accurate_predictions.append(1)\n",
    "    else:\n",
    "        accurate_predictions.append(0)\n",
    "\n",
    "# Calculating the Accuracy\n",
    "accuracy = sum(accurate_predictions) / len(predicted_labels) * 100\n",
    "\n",
    "# printing predicted positive and predicted negative\n",
    "print(f\"Class Distribution - Predicted Positive: {positive_predicted} | Predicted Negative: {negative_predicted}\")\n",
    "\n",
    "# Printing the Accuracy\n",
    "print(f\"Predicted Accuracy : {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
